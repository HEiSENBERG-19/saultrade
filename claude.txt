creds/config.yaml
redis:
  host: localhost
  port: 6379

influxdb:
  url: "http://localhost:8086"
  token: "vvYwJIrzq9vkWTbh_-WgdBsD_OOJ6_5QBhrO8ATrdvaC8_LRSpHgld7gbuIMD2TArjg5pi9D1nrWvBkYCDx9yg=="
  org: "myorg"
  bucket: "mybuk"

creds/tbs_rules.yaml
...

config.py
import yaml
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

class Config:
    def __init__(self, config_file: str, rules_file: str):
        self._config: Dict[str, Any] = self._load_config(config_file)
        self._rules: Dict[str, Any] = self._load_config(rules_file)

    def _load_config(self, file_path: str) -> Dict[str, Any]:
        try:
            with open(file_path, 'r') as file:
                return yaml.safe_load(file)
        except Exception as e:
            logger.error(f"Error loading configuration from {file_path}: {e}", exc_info=True)
            return {}

    def get_config(self, key: str, default: Optional[Any] = None) -> Any:
        return self._config.get(key, default)
    
    def get_rule(self, key: str, default: Optional[Any] = None) -> Any:
        return self._rules.get(key, default)

    def get_redis_config(self) -> Dict[str, Any]:
        return self._config.get('redis', {})

    def get_influxdb_config(self) -> Dict[str, Any]:
        return self._config.get('influxdb', {})

    def get_simulation_duration(self) -> int:
        return self._config.get('simulation_duration', 60)
    
database_manager.py
import redis.asyncio as aioredis
from influxdb_client import InfluxDBClient
from influxdb_client.client.write_api import SYNCHRONOUS
from typing import Optional
import logging

logger = logging.getLogger(__name__)

class DatabaseManager:
    def __init__(self, config):
        self.config = config
        self.redis: Optional[aioredis.Redis] = None
        self.influxdb: Optional[InfluxDBClient] = None

    async def connect_redis(self) -> aioredis.Redis:
        try:
            redis_config = self.config.get_redis_config()
            self.redis = await aioredis.from_url(
                f"redis://{redis_config.get('host', 'localhost')}:{redis_config.get('port', 6379)}"
            )
            return self.redis
        except Exception as e:
            logger.error(f"Failed to connect to Redis: {e}", exc_info=True)
            raise

    def connect_influxdb(self) -> InfluxDBClient:
        try:
            influxdb_config = self.config.get_influxdb_config()
            self.influxdb = InfluxDBClient(
                url=influxdb_config.get('url'),
                token=influxdb_config.get('token'),
                org=influxdb_config.get('org')
            )
            return self.influxdb
        except Exception as e:
            logger.error(f"Failed to connect to InfluxDB: {e}", exc_info=True)
            raise

    async def close(self):
        try:
            if self.redis:
                await self.redis.close()
            if self.influxdb:
                self.influxdb.close()
        except Exception as e:
            logger.error(f"Error while closing database connections: {e}", exc_info=True)

docker-compose.yml
services:
  influxdb:
    image: influxdb:latest
    container_name: influxdb
    ports:
      - "8086:8086"
    environment:
      - INFLUXDB_DB=mydb
      - INFLUXDB_ADMIN_USER=admin
      - INFLUXDB_ADMIN_PASSWORD=admin123
    volumes:
      - influxdb_data:/var/lib/influxdb

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=password
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  influxdb_data:
  grafana_data:

influxdb_manager.py       
from influxdb_client import InfluxDBClient, Point, WritePrecision
from influxdb_client.client.write_api import SYNCHRONOUS
from datetime import datetime
from logger_setup import app_logger

class InfluxDBManager:
    def __init__(self, url, token, org, bucket):
        self.client = InfluxDBClient(url=url, token=token)
        self.write_api = self.client.write_api(write_options=SYNCHRONOUS)
        self.query_api = self.client.query_api()
        self.bucket = bucket
        self.org = org

    def write_data(self, measurement, fields, tags=None):
        try:
            point = Point(measurement)
            for key, value in fields.items():
                if isinstance(value, (int, float)):
                    point = point.field(key, value)
                else:
                    point = point.tag(key, str(value))
            if tags:
                for key, value in tags.items():
                    point = point.tag(key, str(value))
            
            point = point.time(datetime.utcnow(), WritePrecision.NS)
            
            self.write_api.write(bucket=self.bucket, org=self.org, record=point)
        except Exception as e:
            app_logger.error(f"Error writing to InfluxDB: {e}")

    def query_data(self, measurement, start="-1h"):
        try:
            query = f'''
            from(bucket:"{self.bucket}")
                |> range(start: {start})
                |> filter(fn: (r) => r._measurement == "{measurement}")
            '''
            result = self.query_api.query(org=self.org, query=query)
            
            for table in result:
                for record in table.records:
                    yield {
                        'time': record.get_time(),
                        'measurement': record.get_measurement(),
                        'field': record.get_field(),
                        'value': record.get_value()
                    }
        except Exception as e:
            app_logger.error(f"Error querying data from InfluxDB: {e}")
            yield None

    def write_test_point(self):
        self.write_data("tick_data", {"last_price": 100.0})

    def query_test_points(self):
        return list(self.query_data("tick_data"))

    def close(self):
        self.client.close()

models.py           


utils.py
import logging, pyotp, pandas as pd, zipfile, requests, asyncio
from io import BytesIO
from NorenRestApiPy.NorenApi import NorenApi
from logger_setup import app_logger

logger = logging.getLogger(__name__)

def login(config):
    class ShoonyaApiPy(NorenApi):
        def __init__(self):
            NorenApi.__init__(self, host='https://api.shoonya.com/NorenWClientTP/', websocket='wss://api.shoonya.com/NorenWSTP/')

    api = ShoonyaApiPy()        
    factor2 = pyotp.TOTP(config.get_config('secret')).now()
    
    try:
        ret = api.login(
            userid=config.get_config('user'),
            password=config.get_config('pwd'),
            twoFA=factor2,
            vendor_code=config.get_config('vc'),
            api_secret=config.get_config('app_key'),
            imei=config.get_config('imei')
        )
        
        if ret and 'request_time' in ret:
            app_logger.info(f"Login Successful: {ret['request_time']}")
            return api
        else:
            app_logger.error(f"Login failed with response: {ret}")
            return None
    except Exception as e:
        app_logger.error(f"Error during login: {e}", exc_info=True)
        return None

def get_quotes(api, exchange, token):
    try:
        return api.get_quotes(exchange=exchange, token=token)
    except Exception as e:
        app_logger.error(f"Error getting quotes: {e}")
        return None

def fetch_symbols(url: str, file_name: str) -> pd.DataFrame:
    try:
        response = requests.get(url)
        response.raise_for_status() 
        content = response.content

        with zipfile.ZipFile(BytesIO(content)) as z:
            symbols = pd.read_csv(z.open(file_name), delimiter=',')
        
        return symbols
    except Exception as e:
        app_logger.error(f"Error while fetching symbols from {url}: {e}", exc_info=True)
        return None
    
async def get_atm_strike(tsymbol: str, get_quotes_func) -> float:
    symbol_map = {
        'NIFTY': ('Nifty 50', 50, 'NSE', 'INDEX'),
        'BANKNIFTY': ('Nifty Bank', 100, 'NSE', 'INDEX'),
        'FINNIFTY': ('Nifty Fin Services', 50, 'NSE', 'INDEX'),
        'MIDCPNIFTY': ('NIFTY MID SELECT', 50, 'NSE', 'INDEX'),
        'CRUDEOILM': ('CRUDEOILM', 100, 'MCX', 'FUTCOM'), 
        'CRUDEOIL': ('CRUDEOIL', 100, 'MCX', 'FUTCOM'),
        'GOLD': ('GOLD', 100, 'MCX', 'FUTCOM'),
        'GOLDM': ('GOLDM', 100, 'MCX', 'FUTCOM'),
        'COPPER': ('COPPER', 100, 'MCX', 'FUTCOM'),
        'SILVERM': ('SILVERM', 100, 'MCX', 'FUTCOM'),
        'SILVER': ('SILVER', 100, 'MCX', 'FUTCOM'),
        'NATURALGAS': ('NATURALGAS', 100, 'MCX', 'FUTCOM'),
        'ZINC': ('ZINC', 100, 'MCX', 'FUTCOM'),
    }
    
    try:
        if tsymbol not in symbol_map:
            raise ValueError(f"Invalid tsymbol: {tsymbol}")
        
        symbol, base, exchange, instrument = symbol_map[tsymbol]
        
        fno_scrips = fetch_symbols(f'https://api.shoonya.com/{exchange}_symbols.txt.zip', f'{exchange}_symbols.txt')
        if fno_scrips is None:
            raise ValueError(f"Failed to fetch symbols for {exchange}")
        
        fut_token = str(fno_scrips[(fno_scrips['Instrument'] == instrument) & (fno_scrips['Symbol'] == symbol)].iloc[0]['Token'])
        quotes = get_quotes_func(exchange, fut_token)
        
        if not quotes or 'lp' not in quotes:
            raise ValueError("Invalid response from quotes API")

        fut = float(quotes['lp'])
        atm_strike = round(fut / base) * base
        app_logger.info(f'{symbol} ATM: {atm_strike}')
        return atm_strike
    except Exception as e:
        app_logger.error(f"Error while fetching ATM strike: {e}", exc_info=True)
        return None

async def get_option_symbols(tsymbol: str, strikes: dict) -> dict:
    try:
        exchange = 'NFO' if tsymbol in ['NIFTY', 'BANKNIFTY', 'FINNIFTY', 'MIDCPNIFTY'] else 'MCX'
        file_url = f'https://api.shoonya.com/{exchange}_symbols.txt.zip'
        file_name = f'{exchange}_symbols.txt'
        
        fno_scrips = fetch_symbols(file_url, file_name)
        if fno_scrips is None:
            raise ValueError(f"Failed to fetch option symbols for {exchange}")
        
        fno_scrips['Expiry'] = pd.to_datetime(fno_scrips['Expiry'], format='%d-%b-%Y')
        fno_scrips['StrikePrice'] = fno_scrips['StrikePrice'].astype(float)
        fno_scrips.sort_values('Expiry', inplace=True)
        fno_scrips.reset_index(drop=True, inplace=True)

        options = {}
        for opt_key, strike_info in strikes.items():
            strike, option_type = strike_info
            row = fno_scrips[(fno_scrips['Symbol'] == tsymbol) &
                             (fno_scrips['OptionType'] == option_type) &
                             (fno_scrips['StrikePrice'] == strike)]
            if row.empty:
                raise ValueError(f"No option found for {opt_key} with strike {strike} and type {option_type}")
            options[opt_key] = {
                'Exchange': row.iloc[0]['Exchange'],
                'Token': int(row.iloc[0]['Token']),
                'LotSize': int(row.iloc[0]['LotSize']),
                'Symbol': row.iloc[0]['Symbol'],
                'TradingSymbol': row.iloc[0]['TradingSymbol'],
                'Expiry': row.iloc[0]['Expiry'],
                'Instrument': row.iloc[0]['Instrument'],
                'OptionType': row.iloc[0]['OptionType'],
                'StrikePrice': float(row.iloc[0]['StrikePrice'])
            }
        
        app_logger.info(f"Symbols Obtained")
        return options
    except Exception as e:
        app_logger.error(f"Error while fetching option symbols: {e}", exc_info=True)
        return None
    
def adjust_quantity_for_lot_size(quantity: int, lot_size: int) -> int:
    final_quantity = quantity * lot_size
    app_logger.info(f"Final quantity to be used: {final_quantity}")
    return final_quantity

async def get_account_limits(api):
    try:
        limits = await asyncio.to_thread(api.get_limits)
        if limits and limits.get('stat') == 'Ok':
            return limits
        else:
            logger.error(f"Failed to fetch account limits: {limits}")
            return None
    except Exception as e:
        logger.error(f"Error fetching account limits: {e}", exc_info=True)
        return None

logger_setup.py  
import logging

def setup_logger(name, log_file, level=logging.INFO, formatter=None):
    handler = logging.FileHandler(log_file, encoding='utf-8')
    handler.setLevel(level)
    if formatter:
        handler.setFormatter(formatter)
    else:
        handler.setFormatter(logging.Formatter('%(asctime)s.%(msecs)03d - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S'))
    
    logger = logging.getLogger(name)
    logger.setLevel(level)
    logger.addHandler(handler)
    return logger

common_formatter = logging.Formatter('%(asctime)s.%(msecs)03d - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

# Set up the main application logger
app_logger = setup_logger('app', 'logs/my_app.log', formatter=common_formatter)

# Set up the WebSocket logger
ws_logger = setup_logger('websocket', 'logs/ws_logs.log', formatter=common_formatter)

# Set up the PNL logger
pnl_logger = setup_logger('pnl', 'logs/pnl.log', formatter=common_formatter)

# Set up the position logger
pos_logger = setup_logger('pos', 'logs/positions.log', formatter=common_formatter)

websocket_manager.py
import asyncio
import redis.asyncio as aioredis
import json
from logger_setup import app_logger, ws_logger
from queue import Queue
from threading import Thread

class WebSocketManager:
    def __init__(self, api):
        self.api = api
        self.redis = None
        self.feed_opened = False
        self.message_queue = Queue()
        self.processing_task = None

    async def connect(self):
        self.redis = await aioredis.from_url("redis://localhost")
        await self.start_websocket()
        self.processing_task = asyncio.create_task(self.process_queue())

    async def start_websocket(self):
        def run_websocket():
                self.api.start_websocket(
                order_update_callback=self.sync_event_handler_order_update,
                subscribe_callback=self.sync_event_handler_feed_update,
                socket_open_callback=self.open_callback
            )

        Thread(target=run_websocket, daemon=True).start()

    def sync_event_handler_feed_update(self, tick_data):
        self.message_queue.put(('feed_update', tick_data))

    def sync_event_handler_order_update(self, order):
        self.message_queue.put(('order_update', order))

    async def process_queue(self):
        while True:
            while not self.message_queue.empty():
                message_type, data = self.message_queue.get()
                if message_type == 'feed_update':
                    await self.event_handler_feed_update(data)
                elif message_type == 'order_update':
                    await self.event_handler_order_update(data)
            await asyncio.sleep(0.1)  # Small delay to prevent busy waiting

    async def event_handler_feed_update(self, tick_data):
        # ws_logger.info(f"feed update: {tick_data}")
        await self.redis.publish('market_data', json.dumps(tick_data))

    async def event_handler_order_update(self, order):
        ws_logger.info(f"order update: {order}")
        await self.redis.publish('order_updates', json.dumps(order))

    def open_callback(self):
        self.feed_opened = True
        ws_logger.info("WebSocket feed opened")

    async def subscribe_symbol(self, exchange, token, trading_symbol):
        try:
            self.api.subscribe(f'{exchange}|{token}')
            ws_logger.info(f"Subscribed to symbol: {trading_symbol}")
        except Exception as e:
            app_logger.error(f"Error subscribing to {exchange}|{token}: {e}")

    async def unsubscribe_symbol(self, exchange, token, trading_symbol):
        try:
            self.api.unsubscribe(f'{exchange}|{token}')
            ws_logger.info(f"Unsubscribed from symbol: {trading_symbol}")
        except Exception as e:
            app_logger.error(f"Error unsubscribing from {exchange}|{token}: {e}")

    async def close(self):
        if self.processing_task:
            self.processing_task.cancel()
        await self.redis.close()

order_execution_engine.py
import redis.asyncio as aioredis
import json
from logger_setup import app_logger

class OrderExecutionEngine:
    def __init__(self, market_data_processor, position_manager):
        self.redis = None
        self.market_data_processor = market_data_processor
        self.position_manager = position_manager

    async def connect(self):
        self.redis = await aioredis.from_url("redis://localhost")

    async def place_order(self, order_details):
        order_id = await self.generate_order_id()
        order_details['order_id'] = order_id

        ltp = await self.market_data_processor.get_ltp(order_details['symbol'])
        if ltp is None:
            app_logger.error(f"Unable to get LTP for {order_details['symbol']}. Order not placed.")
            return None

        if order_details['order_type'] == 'MKT':
            order_details['price'] = ltp
        elif order_details['order_type'] == 'SL-M':
            order_details['trigger_price'] = order_details['trigger_price']

        await self.redis.set(f"order:{order_id}", json.dumps(order_details))

        await self.redis.publish('orders', json.dumps(order_details))
        
        price_info = f"@ {order_details['price']}" if 'price' in order_details else f"trigger @ {order_details['trigger_price']}"
        app_logger.info(f"Order placed: {order_details['symbol']} {order_details['direction']} {order_details['quantity']} {price_info}")
        
        return order_details

    async def generate_order_id(self):
        return await self.redis.incr('order_id_counter')

    def is_sl_triggered(self, order, ltp):
        if order['direction'] == 'B':
            return ltp >= order['trigger_price']
        else:
            return ltp <= order['trigger_price']

    async def execute_stop_loss(self, sl_order_id):
        sl_order = await self.redis.get(f"order:{sl_order_id}")
        if not sl_order:
            app_logger.error(f"Stop loss order {sl_order_id} not found")
            return False

        sl_order = json.loads(sl_order)
        
        ltp = await self.market_data_processor.get_ltp(sl_order['symbol'])
        if ltp is None:
            app_logger.error(f"Unable to get LTP for {sl_order['symbol']}. Stop loss not executed.")
            return False

        if self.is_sl_triggered(sl_order, ltp):
            await self.position_manager.update_position(sl_order['symbol'], ltp)
            
            await self.redis.delete(f"order:{sl_order_id}")
            return True

        return False   
    
    async def close(self):
        await self.redis.close()

simulation.py
import redis.asyncio as aioredis
import asyncio
import os
import subprocess
from logger_setup import app_logger
from position_manager import PositionManager
from websocket_manager import WebSocketManager
from market_data_processor import MarketDataProcessor
from order_execution_engine import OrderExecutionEngine
from config import Config
from utils import login
from influxdb_manager import InfluxDBManager
from margin_calculator import MarginCalculator
from straddle import Straddle

class SimulationManager:
    def __init__(self, config, api):
        self.config = config
        influxdb_config = self.config.get_influxdb_config()
        self.api = api
        self.websocket_manager = WebSocketManager(api)
        self.market_data_processor = MarketDataProcessor()
        self.redis = None
        self.influxdb_manager = InfluxDBManager(
            url=influxdb_config.get('url'),
            token=influxdb_config.get('token'),
            org=influxdb_config.get('org'),
            bucket=influxdb_config.get('bucket')
        )
        self.position_manager = PositionManager(self.market_data_processor, self.influxdb_manager)
        self.order_execution_engine = OrderExecutionEngine(self.market_data_processor, self.position_manager)
        self.margin_calculator = MarginCalculator(api, config.get_config('user'))
        self.strategy = Straddle(config, api, self.websocket_manager, self.market_data_processor, 
                                 self.position_manager, self.order_execution_engine, self.margin_calculator)

    async def setup(self):
        await self.websocket_manager.connect()
        await self.market_data_processor.connect()
        await self.order_execution_engine.connect()
        self.redis = await aioredis.from_url("redis://localhost")

    async def cleanup(self):
        self.influxdb_manager.close()
        await self.websocket_manager.close()
        await self.market_data_processor.close()
        await self.order_execution_engine.close()
        await self.redis.aclose()  # Changed to aclose()

    async def run(self):
        app_logger.info("Starting simulation.")
        await self.setup()

        while not self.websocket_manager.feed_opened:
            await asyncio.sleep(0.1)
        
        app_logger.info("WebSocket connected. Proceeding with simulation.")

        option_symbols, final_quantity, final_trade_margin, atm_strike = await self.strategy.setup()
        if not option_symbols or final_quantity <= 0:
            app_logger.error("Strategy setup failed. Aborting simulation.")
            await self.cleanup()
            return

        await self.strategy.execute(option_symbols, final_quantity, atm_strike)

        await self.cleanup()

async def start_redis_server(redis_dir):
    try:
        os.chdir(redis_dir)
        process = subprocess.Popen(['redis-server'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print("Redis server started.")
    except Exception as e:
        print(f"Failed to start Redis server: {e}")

async def start_docker_compose():
    try:
        process = subprocess.Popen(['docker-compose', 'start'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print("Docker containers started.")
    except Exception as e:
        print(f"Failed to start Docker containers: {e}")

async def main():
    redis_dir = r'redis'
    
    await asyncio.gather(
        start_redis_server(redis_dir),
        start_docker_compose()
    )
    
    config = Config('/home/heisenberg/saultrade/creds/config.yaml', '/home/heisenberg/saultrade/creds/tbs_rules.yaml')
    api = login(config)
    
    simulation = SimulationManager(config, api)
    await simulation.run()

if __name__ == "__main__":
    asyncio.run(main())

margin_calculator.py   
import logging, asyncio
from NorenRestApiPy.NorenApi import position
from utils import get_account_limits  
from logger_setup import app_logger

class MarginCalculator:
    def __init__(self, api, account_id):
        self.api = api
        self.account_id = account_id

    async def calculate_margin(self, option_symbols, adjusted_quantity):
        try:
            position_list = self._create_position_list(option_symbols, adjusted_quantity)
            margin_result = await self._calculate_span(position_list)
            
            if margin_result and 'stat' in margin_result and margin_result['stat'] == 'Ok':
                span = float(margin_result.get('span', 0))
                expo = float(margin_result.get('expo', 0))
                span_trade = float(margin_result.get('span_trade', 0))
                expo_trade = float(margin_result.get('expo_trade', 0))
                
                margin = span + expo
                trade_margin = span_trade + expo_trade
                
                final_margin = round(margin * 1.009, 2)
                final_trade_margin = round(trade_margin * 1.009, 2)
                app_logger.info(f"Required margin: {final_trade_margin}")
                return final_margin, final_trade_margin
            else:
                app_logger.error(f"Error in margin calculation: {margin_result}")
                return None
        except Exception as e:
            app_logger.error(f"Error in calculate_margin: {e}", exc_info=True)
            return None

    def _create_position_list(self, option_symbols, adjusted_quantity):
        position_list = []
        for key, symbol_data in option_symbols.items():
            pos = position()
            pos.prd = 'I'  # Assuming NRML product type, change if needed
            pos.exch = symbol_data['Exchange']
            pos.instname = symbol_data['Instrument']
            pos.symname = symbol_data['Symbol']
            pos.exd = symbol_data['Expiry'].strftime('%d-%b-%Y').upper()
            pos.optt = symbol_data['OptionType']
            pos.strprc = str(symbol_data['StrikePrice'])
            pos.buyqty = '0'
            pos.sellqty = str(adjusted_quantity)
            pos.netqty = ''
            position_list.append(pos)
        return position_list

    async def _calculate_span(self, position_list):
        try:
            return await asyncio.to_thread(self.api.span_calculator, self.account_id, position_list)
        except Exception as e:
            app_logger.error(f"Error in _calculate_span: {e}", exc_info=True)
            return None

    async def get_available_margin(self) -> float:
        """Fetch and return the available margin for the account."""
        account_limits = await get_account_limits(self.api)
        if not account_limits:
            app_logger.warning("Failed to fetch account limits.")
            return 0
        return float(account_limits.get('cash', 0))

    async def calculate_max_quantity(self, option_symbols, lot_size: int):
        """Calculate the maximum quantity that can be traded based on available margin."""
        available_margin = await self.get_available_margin()
        app_logger.info(f"Available margin: {available_margin}")

        one_lot_margin = await self.calculate_margin(option_symbols, lot_size)
        if one_lot_margin is None:
            app_logger.warning("Failed to calculate margin for one lot.")
            return 0

        max_lots = int(available_margin / one_lot_margin[1])  # Using final_trade_margin
        app_logger.info(f"Maximum lots that can be traded: {max_lots}")

        return max_lots * lot_size

position_manager.py        
import asyncio
from logger_setup import app_logger, pnl_logger

class PositionManager:
    def __init__(self, market_data_processor, influxdb_manager):
        self.positions = {}
        self.market_data_processor = market_data_processor
        self.total_entry_value = 0
        self.total_current_value = 0
        self.influxdb_manager = influxdb_manager
        self.trade_margin = 0
    
    def set_trade_margin(self, margin):
        self.trade_margin = margin

    async def add_position(self, symbol, quantity, price):
        self.positions[symbol] = {
            'quantity': quantity,
            'entry_price': price,
            'current_price': price
        }
        self.total_entry_value += quantity * price
        self.total_current_value += quantity * price
        
        self.influxdb_manager.write_data(
            measurement="positions",
            fields={"quantity": quantity, "price": price},
            tags={"symbol": symbol, "action": "add"}
        )

    async def update_position(self, symbol, new_price):
        if symbol in self.positions:
            old_price = self.positions[symbol]['current_price']
            quantity = self.positions[symbol]['quantity']
            entry_price = self.positions[symbol]['entry_price']
            self.positions[symbol]['current_price'] = new_price
            self.total_current_value += quantity * (new_price - old_price)
            
            position_pnl = (entry_price - new_price) * quantity
            await self.calculate_pnl()
            
            self.influxdb_manager.write_data(
                measurement="positions",
                fields={"price": new_price, "pnl": position_pnl},
                tags={"symbol": symbol}
            )

    async def calculate_pnl(self):
            total_pnl = self.total_entry_value - self.total_current_value
            roi = 0
            if self.total_entry_value != 0:
                if self.trade_margin != 0:
                    roi = (total_pnl / self.trade_margin) * 100
                self.influxdb_manager.write_data(
                    measurement="pnl",
                    fields={
                        "total_pnl": total_pnl, 
                        "roi": roi,
                    }
                )
            return total_pnl, roi

    async def get_total_pnl(self):
        return await self.calculate_pnl()

    async def check_stop_loss(self, symbol, stop_loss_price):
        if symbol in self.positions:
            current_price = self.positions[symbol]['current_price']
            if current_price >= stop_loss_price:
                return True
        return False

    async def get_all_positions(self):
        return self.positions

straddle.py
import asyncio
from logger_setup import app_logger, pos_logger
from utils import get_atm_strike, get_option_symbols, adjust_quantity_for_lot_size

class Straddle:
    def __init__(self, config, api, websocket_manager, market_data_processor, position_manager, order_execution_engine, margin_calculator):
        self.config = config
        self.api = api
        self.websocket_manager = websocket_manager
        self.market_data_processor = market_data_processor
        self.position_manager = position_manager
        self.order_execution_engine = order_execution_engine
        self.margin_calculator = margin_calculator
        self.stop_loss_percentage = self.config.get_rule('stop_loss_percentage') / 100

    async def setup(self):
        option_symbols, atm_strike = await self._get_option_symbols()
        if not option_symbols:
            return None, None, 0, None

        final_quantity = await self._calculate_final_quantity(option_symbols)
        if final_quantity <= 0:
            return None, None, 0, None

        final_margin, final_trade_margin = await self._calculate_margin(option_symbols, final_quantity)
        
        await self.subscribe_to_symbols(option_symbols)
        
        await asyncio.sleep(1)

        return option_symbols, final_quantity, final_trade_margin, atm_strike

    async def execute(self, option_symbols, final_quantity, atm_strike):
        initial_order_details = await self.place_initial_orders(option_symbols, final_quantity)
        stop_loss_orders = await self.place_stop_loss_orders(initial_order_details, final_quantity)

        await self.monitor_positions_and_stop_loss(stop_loss_orders, option_symbols, final_quantity)

        final_pnl, roi = await self.position_manager.calculate_pnl()
        app_logger.info(f"Final P&L: Rs{final_pnl:.2f}")
        app_logger.info(f"Final ROI: {roi:.2f}%")

        await self.unsubscribe_from_symbols(option_symbols)

    async def _get_option_symbols(self):
        try:
            atm_strike = await get_atm_strike(
                self.config.get_rule('tsymbol'), 
                lambda e, t: self.api.get_quotes(e, t)
            )
            if not atm_strike:
                app_logger.error("Failed to get ATM strike. Aborting simulation.")
                return None, None
            
            strikes = {
                'sce': (atm_strike + self.config.get_rule('sotm_points') + self.config.get_rule('bias_points'), 'CE'),
                'spe': (atm_strike - self.config.get_rule('sotm_points') + self.config.get_rule('bias_points'), 'PE'),
            }
            option_symbols = await get_option_symbols(self.config.get_rule('tsymbol'), strikes)
            if not option_symbols:
                app_logger.error("Failed to get option symbols. Aborting simulation.")
                return None, None
            return option_symbols, atm_strike
        except Exception as e:
            app_logger.error(f"Error getting option symbols: {e}")
            return None, None

    async def subscribe_to_symbols(self, option_symbols):
        for symbol in option_symbols.values():
            await self.websocket_manager.subscribe_symbol(symbol['Exchange'], symbol['Token'], symbol['TradingSymbol'])

    async def unsubscribe_from_symbols(self, option_symbols):
        for symbol in option_symbols.values():
            await self.websocket_manager.unsubscribe_symbol(symbol['Exchange'], symbol['Token'], symbol['TradingSymbol'])

    async def _calculate_final_quantity(self, option_symbols):
        final_quantity = int(adjust_quantity_for_lot_size(self.config.get_rule('quantity'), option_symbols['sce']['LotSize']))

        if final_quantity <= 0:
            app_logger.error("Final quantity <= zero. Aborting simulation.")
            return 0

        return final_quantity
    
    async def _calculate_margin(self, option_symbols, final_quantity):
        required_margin, final_trade_margin = await self.margin_calculator.calculate_margin(option_symbols, final_quantity)
        self.position_manager.set_trade_margin(final_trade_margin)
        return required_margin, final_trade_margin   
   
    async def place_initial_orders(self, option_symbols, final_quantity):
        initial_order_details = []
        for symbol in option_symbols.values():
            order = {
                'symbol': symbol['TradingSymbol'],
                'direction': 'S',
                'quantity': final_quantity,
                'order_type': 'MKT'
            }
            order_response = await self.order_execution_engine.place_order(order)
            if order_response:
                order_id = order_response['order_id']
                executed_price = order_response['price']
                
                await self.position_manager.add_position(symbol['TradingSymbol'], final_quantity, executed_price)
                initial_order_details.append({
                    'symbol': symbol['TradingSymbol'],
                    'order_id': order_id,
                    'executed_price': executed_price
                })
                pos_logger.info(f"Position opened for {symbol['TradingSymbol']} at {executed_price}")
        return initial_order_details

    async def place_stop_loss_orders(self, initial_order_details, final_quantity):
        stop_loss_orders = []
        for order_detail in initial_order_details:
            sl_price = round(order_detail['executed_price'] * (1 + self.stop_loss_percentage), 2)
            
            sl_order = {
                'symbol': order_detail['symbol'],
                'direction': 'B',
                'quantity': final_quantity,
                'order_type': 'SL-M',
                'trigger_price': sl_price,
                'parent_order_id': order_detail['order_id']
            }
            sl_order_response = await self.order_execution_engine.place_order(sl_order)
            if sl_order_response:
                stop_loss_orders.append({
                    'symbol': order_detail['symbol'],
                    'sl_order_id': sl_order_response['order_id'],
                    'sl_price': sl_price
                })
        return stop_loss_orders

    async def monitor_positions_and_stop_loss(self, stop_loss_orders, option_symbols, final_quantity):
        while True:
            positions = await self.position_manager.get_all_positions()
            
            if not positions:
                app_logger.info("All positions closed. Exiting simulation.")
                return

            positions_copy = dict(positions)

            for symbol, position in positions_copy.items():
                if symbol not in positions:
                    continue

                current_price = await self.market_data_processor.get_ltp(symbol)
                if current_price:
                    await self.position_manager.update_position(symbol, current_price)

                    for sl_order in stop_loss_orders[:]:
                        if sl_order['symbol'] == symbol:
                            if (position['quantity'] > 0 and current_price >= sl_order['sl_price']) or \
                            (position['quantity'] < 0 and current_price <= sl_order['sl_price']):
                                app_logger.info(f"Stop loss triggered for {symbol} at {current_price}")
                                is_executed = await self.order_execution_engine.execute_stop_loss(sl_order['sl_order_id'])
                                if is_executed:
                                    stop_loss_orders.remove(sl_order)
                                    del self.position_manager.positions[symbol]
                                    pos_logger.info(f"Position closed for {symbol} at {current_price}")
                                    break

            await asyncio.sleep(1)

market_data_processor.py 
import asyncio
import redis.asyncio as aioredis
import json
from logger_setup import app_logger

class MarketDataProcessor:
    def __init__(self):
        self.redis = None
        self.token_symbol_map = {}

    async def connect(self):
        self.redis = await aioredis.from_url("redis://localhost")
        asyncio.create_task(self.process_market_data())

    async def process_market_data(self):
        pubsub = self.redis.pubsub()
        await pubsub.subscribe('market_data')
        while True:
            message = await pubsub.get_message(ignore_subscribe_messages=True)
            if message:
                data = json.loads(message['data'])
                await self.update_market_data(data)

    async def update_market_data(self, data):
        if 'lp' in data and 'tk' in data:
            token = data['tk']
            ltp = float(data['lp'])  
            if 'ts' in data:
                symbol = data['ts']
                self.token_symbol_map[token] = symbol
                await self.redis.hset(f'token_symbol_map', token, symbol)
            symbol = self.token_symbol_map.get(token) or await self.redis.hget('token_symbol_map', token)
            if symbol:
                self.token_symbol_map[token] = symbol.decode('utf-8') if isinstance(symbol, bytes) else symbol
            display_id = symbol if symbol else token
            await self.redis.hset(f'market_data:{symbol}', 'ltp', ltp)

    async def get_ltp(self, symbol):
        ltp = await self.redis.hget(f'market_data:{symbol}', 'ltp')
        return float(ltp) if ltp else None

    async def get_ltp_with_retry(self, token, max_retries=5, retry_delay=1):
        for _ in range(max_retries):
            ltp = await self.get_ltp(token)
            if ltp is not None:
                return ltp
            app_logger.warning(f"LTP not available for {token}. Retrying...")
            await asyncio.sleep(retry_delay)
        app_logger.error(f"Failed to get LTP for {token} after {max_retries} retries.")
        return None

    async def close(self):
        await self.redis.close()